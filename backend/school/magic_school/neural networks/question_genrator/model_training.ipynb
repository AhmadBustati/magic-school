{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model_training.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"12IpIBwdvv5G2reskiL9M6PweZVG2ZyKe","authorship_tag":"ABX9TyPURYGig5p9qMt9DqyGSOfz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np \n","import matplotlib.pyplot as plt\n","from transformers import TFT5ForConditionalGeneration"],"metadata":{"id":"6--3Dmdjgjnb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NyiudfpnKNLK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652029162339,"user_tz":-60,"elapsed":11258,"user":{"displayName":"Ahmad Bastati","userId":"07522904177524722153"}},"outputId":"ce844be8-ab78-433f-deec-11d68c3813e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: SentencePiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.1.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.5.1)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}],"source":["!pip install transformers\n","!pip install SentencePiece\n","!pip install datasets"]},{"cell_type":"code","source":["from datasets import load_dataset\n","train_dataset = load_dataset(\"iarfmoose/question_generator\",split=\"train\")\n","val_dataset = load_dataset(\"iarfmoose/question_generator\",split=\"validation\")\n","checkpoint =\"t5-base\"\n","max_length = 256#@param{type:\"slider\",min:256,max:512,step:2}\n","pad_id_mask = -100\n","warmup_steps = 1e4\n","train_batch_size = 8\n","val_batch_size = 16\n","buffer_size = 1000\n","ntrain = len(train_dataset)\n","nvalid = len(val_dataset)\n","steps = int(np.ceil(ntrain/train_batch_size))\n","valid_steps = int(np.ceil(nvalid/val_batch_size))\n","print(\"Total Steps: \", steps)\n","print(\"Total Validation Steps: \", valid_steps)\n"],"metadata":{"id":"0Og7DUtWKRXE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652029168687,"user_tz":-60,"elapsed":6353,"user":{"displayName":"Ahmad Bastati","userId":"07522904177524722153"}},"outputId":"f0f65bbc-877e-442d-bed9-301c630d29a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using custom data configuration iarfmoose--question_generator-20c43e028f253cc6\n","Reusing dataset csv (/root/.cache/huggingface/datasets/csv/iarfmoose--question_generator-20c43e028f253cc6/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n","Using custom data configuration iarfmoose--question_generator-20c43e028f253cc6\n","Reusing dataset csv (/root/.cache/huggingface/datasets/csv/iarfmoose--question_generator-20c43e028f253cc6/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps:  25502\n","Total Validation Steps:  2251\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, T5Tokenizer, TFT5ForConditionalGeneration,T5Config\n","def encode_text(example,max_length=max_length):\n","    \"\"\"\n","    Tokenizes the data in order to have the data model-ready\n","     \"\"\"\n","    text = example[\"text\"]\n","    question = example[\"question\"]\n","    encoded_text= tokenizer(\n","        text,\n","        # text[\"question\"],\n","        padding = \"max_length\",\n","        max_length=max_length,\n","        truncation=True,\n","        return_tensors='tf'\n","    )\n","    encoded_question = tokenizer(\n","        question,\n","        padding=\"max_length\",\n","        max_length=max_length,\n","        truncation=True,\n","        return_tensors = \"tf\"\n","\n","    )\n","    input_ids = encoded_text['input_ids'][0]\n","    input_attention = encoded_text['attention_mask'][0]\n","    target_ids = encoded_question['input_ids'][0]\n","    target_attention = encoded_question['attention_mask'][0]\n","    outputs = {'input_ids':input_ids, 'attention_mask': input_attention, \n","               'labels':target_ids, 'decoder_attention_mask':target_attention}\n","    return outputs\n","\n","def get_tokenizer(checkpoint) :\n","    \"\"\"\n","    This function adds two special tokens <answer>, <context> since these tokens\n","    will be used  \n","     \"\"\"\n","    tokenizer = T5Tokenizer.from_pretrained(checkpoint)\n","    tokenizer.add_special_tokens(\n","        {'additional_special_tokens': ['<answer>', '<context>']}\n","    )\n","    return tokenizer\n","\n","def create_dataset(dataset, cache_path=None, batch_size=4, \n","                   buffer_size= 1000, shuffling=True):    \n","    if cache_path is not None:\n","        dataset = dataset.cache(cache_path)        \n","    if shuffling:\n","        dataset = dataset.shuffle(buffer_size)\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","    return dataset\n","\n","def to_tf_dataset(dataset):  \n","  columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n","  dataset.set_format(type='tensorflow', columns=columns)\n","  return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, \n","                'labels':tf.int32, 'decoder_attention_mask':tf.int32,  }\n","  return_shapes = {'input_ids': tf.TensorShape([None]), 'attention_mask': tf.TensorShape([None]), \n","                  'labels': tf.TensorShape([None]), 'decoder_attention_mask':tf.TensorShape([None])}\n","  ds = tf.data.Dataset.from_generator(lambda : dataset, return_types, return_shapes)\n","  return ds\n","  \n","\n","    \n","class SnapthatT5(TFT5ForConditionalGeneration):\n","    def __init__(self, *args, log_dir=None, cache_dir= None, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.loss_tracker= tf.keras.metrics.Mean(name='loss') \n","    \n","    @tf.function\n","    def train_step(self, data):\n","        x = data\n","        y = x[\"labels\"]\n","        y = tf.reshape(y, [-1, 1])\n","        with tf.GradientTape() as tape:\n","            outputs = self(x, training=True)\n","            loss = outputs[0]\n","            logits = outputs[1]\n","            loss = tf.reduce_mean(loss)\n","            \n","            grads = tape.gradient(loss, self.trainable_variables)\n","            \n","        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n","        lr = self.optimizer._decayed_lr(tf.float32)\n","        \n","        self.loss_tracker.update_state(loss)        \n","        self.compiled_metrics.update_state(y, logits)\n","        metrics = {m.name: m.result() for m in self.metrics}\n","        metrics.update({'lr': lr})\n","        \n","        return metrics\n","\n","    def test_step(self, data):\n","        x = data\n","        y = x[\"labels\"]\n","        y = tf.reshape(y, [-1, 1])\n","        output = self(x, training=False)\n","        loss = output[0]\n","        loss = tf.reduce_mean(loss)\n","        logits = output[1]\n","        \n","        self.loss_tracker.update_state(loss)\n","        self.compiled_metrics.update_state(y, logits)\n","        return {m.name: m.result() for m in self.metrics}\n","        "],"metadata":{"id":"E_wJDGR7KUwS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = get_tokenizer(checkpoint)\n","train_ds = train_dataset.map(encode_text)\n","val_ds = val_dataset.map(encode_text)\n","tf_train_ds = to_tf_dataset(train_ds)\n","tf_val_ds = to_tf_dataset(val_ds)\n","\n","tf_train_ds= create_dataset(tf_train_ds, batch_size=train_batch_size, \n","                         shuffling=True, cache_path = None)\n","tf_val_ds = create_dataset(tf_val_ds, batch_size=val_batch_size, \n","                         shuffling=False, cache_path = None)\n"],"metadata":{"id":"FTk_cFXdLWED","executionInfo":{"status":"ok","timestamp":1652029172983,"user_tz":-60,"elapsed":3853,"user":{"displayName":"Ahmad Bastati","userId":"07522904177524722153"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8226ede5-95a9-4554-9518-9ef97ae28b1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/iarfmoose--question_generator-20c43e028f253cc6/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-dc74b78c655d2935.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/iarfmoose--question_generator-20c43e028f253cc6/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-704c7ca57d6b3023.arrow\n"]}]},{"cell_type":"code","source":["# Creating a tensorboard log to check the progress of the model\n","import os \n","import datetime \n","%load_ext tensorboard\n","start_profile_batch = steps+10\n","stop_profile_batch = start_profile_batch + 100\n","profile_range = f\"{start_profile_batch},{stop_profile_batch}\"\n","log_dir = os.path.join(\"./logs\",\n","                        # Make it so the logs get tracked whenever we run an experiment \n","                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","save_path = \"./models\"#@param {type:\"string\"}\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,\n","                                                      update_freq=20,profile_batch=profile_range)\n","checkpoint_filepath = save_path + \"/\" + \"T5-{epoch:04d}-{val_loss:.4f}.ckpt\"\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=False,\n","    monitor='val_loss',\n","    mode='min',\n","    save_best_only=True)\n","\n","callbacks = [tensorboard_callback, model_checkpoint_callback] \n","metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy') ]\n","optimizer = tf.keras.optimizers.Adam(0.00001)\n","loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n","model = SnapthatT5.from_pretrained(checkpoint)\n","model.compile(optimizer=optimizer, metrics=metrics,loss=loss)"],"metadata":{"id":"3wOiVcj8LOvs","executionInfo":{"status":"ok","timestamp":1652029180041,"user_tz":-60,"elapsed":7061,"user":{"displayName":"Ahmad Bastati","userId":"07522904177524722153"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ed056032-aefd-4eba-bbef-4743c908c72c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing SnapthatT5.\n","\n","All the layers of SnapthatT5 were initialized from the model checkpoint at t5-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use SnapthatT5 for predictions without further training.\n"]}]},{"cell_type":"code","source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"id":"fA8O9PEFKo_7","executionInfo":{"status":"ok","timestamp":1652029180041,"user_tz":-60,"elapsed":7,"user":{"displayName":"Ahmad Bastati","userId":"07522904177524722153"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2d4af63-f9cc-4833-b40b-c67cb343f43c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","source":["epochs_done = 0\n","model.fit(tf_train_ds, epochs=20, steps_per_epoch=steps, callbacks=callbacks, \n","          validation_data=tf_val_ds, validation_steps=valid_steps, initial_epoch=epochs_done)"],"metadata":{"id":"BSpzsgc1KpaS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2a2c5d22-6fec-4f05-8d78-d46d5f76d110"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n"]}]},{"cell_type":"code","source":["model.save_pretrained (save_path)"],"metadata":{"id":"A4R5K6IeMKDS"},"execution_count":null,"outputs":[]}]}